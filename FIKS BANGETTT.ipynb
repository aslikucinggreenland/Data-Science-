{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878db9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b896e61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.770000e+17</td>\n",
       "      <td>5.770000e+17</td>\n",
       "      <td>@AAlwuhaib1977 Muslim mob violence against Hin...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>@Te4m_NiGhtM4Re http://t.co/5Ih7MkDbQG</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.680000e+17</td>\n",
       "      <td>5.680000e+17</td>\n",
       "      <td>@jncatron @isra_jourisra @AMPalestine Islamoph...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.770000e+17</td>\n",
       "      <td>5.770000e+17</td>\n",
       "      <td>Finally I'm all caught up, and that sudden dea...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.710000e+17</td>\n",
       "      <td>5.710000e+17</td>\n",
       "      <td>@carolinesinders @herecomesfran *hugs*</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464</th>\n",
       "      <td>4.510000e+17</td>\n",
       "      <td>4.510000e+17</td>\n",
       "      <td>@RICANROLL You think your reply is clever? Wom...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13465</th>\n",
       "      <td>5.750000e+17</td>\n",
       "      <td>5.750000e+17</td>\n",
       "      <td>@asem_1994 ISIS beheads people. Saudi beheads ...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13466</th>\n",
       "      <td>5.760000e+17</td>\n",
       "      <td>5.760000e+17</td>\n",
       "      <td>#mkr NOOOOO!!! I wanted Kat and Andre to lose!!!</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>5.580000e+17</td>\n",
       "      <td>5.580000e+17</td>\n",
       "      <td>RT @MumtazCeltik: @WhiteHouse @VP \\n\\n#Kobane ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>5.760000e+17</td>\n",
       "      <td>5.760000e+17</td>\n",
       "      <td>@mykitchenrules #mkr please kick off that lady...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13469 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              index            id  \\\n",
       "0      5.770000e+17  5.770000e+17   \n",
       "1      5.410000e+17  5.410000e+17   \n",
       "2      5.680000e+17  5.680000e+17   \n",
       "3      5.770000e+17  5.770000e+17   \n",
       "4      5.710000e+17  5.710000e+17   \n",
       "...             ...           ...   \n",
       "13464  4.510000e+17  4.510000e+17   \n",
       "13465  5.750000e+17  5.750000e+17   \n",
       "13466  5.760000e+17  5.760000e+17   \n",
       "13467  5.580000e+17  5.580000e+17   \n",
       "13468  5.760000e+17  5.760000e+17   \n",
       "\n",
       "                                                    Text Annotation  oh_label  \n",
       "0      @AAlwuhaib1977 Muslim mob violence against Hin...     racism         1  \n",
       "1                 @Te4m_NiGhtM4Re http://t.co/5Ih7MkDbQG       none         0  \n",
       "2      @jncatron @isra_jourisra @AMPalestine Islamoph...     racism         1  \n",
       "3      Finally I'm all caught up, and that sudden dea...       none         0  \n",
       "4                 @carolinesinders @herecomesfran *hugs*       none         0  \n",
       "...                                                  ...        ...       ...  \n",
       "13464  @RICANROLL You think your reply is clever? Wom...       none         0  \n",
       "13465  @asem_1994 ISIS beheads people. Saudi beheads ...     racism         1  \n",
       "13466   #mkr NOOOOO!!! I wanted Kat and Andre to lose!!!       none         0  \n",
       "13467  RT @MumtazCeltik: @WhiteHouse @VP \\n\\n#Kobane ...       none         0  \n",
       "13468  @mykitchenrules #mkr please kick off that lady...       none         0  \n",
       "\n",
       "[13469 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('twitter_racism_parsed_dataset.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b365fdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_transformed = dataset[['oh_label', 'Text']]\n",
    "y = dt_transformed.iloc[:, :-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e5c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "y = np.array(ct.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377d81eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b9fcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "y_hate = np.array(y_df[0])\n",
    "y_offensive = np.array(y_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbe2816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. ... 1. 1. 1.]\n",
      "[1. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hate)\n",
    "print(y_offensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7caa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range (0, 13469):\n",
    "    review = re.sub(\"[^a-zA-Z]\", ' ', dt_transformed['Text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc781ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 2000)\n",
    "x = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338649f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_hate, test_size = 0.30, random_state = 0)\n",
    "\n",
    "#ERRORRRRRRRR CAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d6b54ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_np = GaussianNB()\n",
    "classifier_np.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dea47d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr = LogisticRegression(random_state = 0)\n",
    "classifier_lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e8f904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svm = svm.SVC()\n",
    "classifier_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d74b39ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 491  107]\n",
      " [1126 2317]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_np = classifier_np.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred_np)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b96dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 414  184]\n",
      " [  90 3353]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = classifier_svm.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ea703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 408  190]\n",
      " [ 103 3340]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = classifier_lr.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b34daecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy: 0.9321950012373175\n",
      "Logistic Regression Accuracy: 0.9274931947537738\n",
      "Naive Bayes Accuracy: 0.6948775055679287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_score = accuracy_score(y_test, y_pred_svm)\n",
    "lr_score = accuracy_score(y_test, y_pred_lr)\n",
    "np_score = accuracy_score(y_test, y_pred_np)\n",
    "\n",
    "print('Support Vector Machine Accuracy:', str(svm_score))\n",
    "print('Logistic Regression Accuracy:', str(lr_score))\n",
    "print('Naive Bayes Accuracy:', str(np_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aebf3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model_SVM'\n",
    "pickle.dump(classifier_svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fd63044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321950012373175\n"
     ]
    }
   ],
   "source": [
    "load_model = pickle.load(open(filename, 'rb'))\n",
    "result = load_model.score(x_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
